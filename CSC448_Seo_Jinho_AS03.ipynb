{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3ucbG-0Vd_n"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PineappleBingo/CSC448-AI/blob/main/CSC448_Seo_Jinho_AS03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "ieJ4qlv5Vd_q"
      },
      "outputs": [],
      "source": [
        "# Imports section\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvpqV3tTVd_r"
      },
      "source": [
        "## Part 1. Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "qoCco9OvVd_r"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Temperature 째C  Mols KCL     Size nm^3\n",
            "0              469       647  6.244743e+05\n",
            "1              403       694  5.779610e+05\n",
            "2              302       975  6.196847e+05\n",
            "3              779       916  1.460449e+06\n",
            "4              901        18  4.325726e+04\n",
            "5              545       637  7.124634e+05\n",
            "6              660       519  7.006960e+05\n",
            "7              143       869  2.718260e+05\n",
            "8               89       461  8.919803e+04\n",
            "9              294       776  4.770210e+05\n",
            "10             991       117  2.441771e+05\n",
            "11             307       781  5.006455e+05\n",
            "12             206        70  3.145200e+04\n",
            "13             437       599  5.390215e+05\n",
            "14             566        75  9.185271e+04\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000 entries, 0 to 999\n",
            "Data columns (total 3 columns):\n",
            " #   Column          Non-Null Count  Dtype  \n",
            "---  ------          --------------  -----  \n",
            " 0   Temperature 째C  1000 non-null   int64  \n",
            " 1   Mols KCL        1000 non-null   int64  \n",
            " 2   Size nm^3       1000 non-null   float64\n",
            "dtypes: float64(1), int64(2)\n",
            "memory usage: 23.6 KB\n",
            "None\n",
            "\n",
            "Row x Columns: (1000, 3)\n",
            "\n",
            "Column Names: Index(['Temperature 째C', 'Mols KCL', 'Size nm^3'], dtype='object')\n"
          ]
        }
      ],
      "source": [
        "# Using pandas load the dataset (load remotely, not locally)\n",
        "CSV_URL = \"https://raw.githubusercontent.com/profmcnich/example_notebook/main/science_data_large.csv\"\n",
        "# s = requests.get(CSV_URL).content\n",
        "# df = pd.read_csv(io.StringIO(s.decode('utf-8')))\n",
        "df = pd.read_csv(CSV_URL)\n",
        "\n",
        "# Output the first 15 rows of the data\n",
        "print(df.head(15))\n",
        "# Display a summary of the table information (number of datapoints, etc.)\n",
        "print(df.info())\n",
        "# Shape\n",
        "print(\"\\nRow x Columns:\", df.shape)\n",
        "# column names\n",
        "print(\"\\nColumn Names:\", df.columns)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OuKtJOpVd_r"
      },
      "source": [
        "## Part 2. Splitting the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "ey692r5EVd_s"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X1_train Shape:(900, 1)\tX1_test Shape: (100, 1)\n",
            "X2_train Shape:(900, 1)\tX2_test Shape: (100, 1)\n",
            "X3_train Shape:(900, 2)\tX3_test Shape: (100, 2)\n",
            "Y_train Shape: (900,)\tY_test Shape:  (100,)\n"
          ]
        }
      ],
      "source": [
        "# Take the pandas dataset and split it into our features (X) and label (y)\n",
        "\n",
        "features = [\"Temperature 째C\", \"Mols KCL\"]\n",
        "target = \"Size nm^3\"\n",
        "\n",
        "X1 = df[features[0]].values.reshape(-1, 1)\n",
        "X2 = df[features[1]].values.reshape(-1, 1)\n",
        "X3 = df[features].values.reshape(-1, len(features))\n",
        "\n",
        "Y = df[target].values\n",
        "\n",
        "# Use sklearn to split the features and labels into a training/test set. (90% train, 10% test)\n",
        "X1_train, X1_test, Y_train, Y_test = train_test_split(X1, Y, test_size=0.1, random_state=10)\n",
        "X2_train, X2_test, Y_train, Y_test = train_test_split(X2, Y, test_size=0.1, random_state=10)\n",
        "X3_train, X3_test, Y_train, Y_test = train_test_split(X3, Y, test_size=0.1, random_state=10)\n",
        "# Set random_state(a.k.a seed) so that we can reproduce our results\n",
        "\n",
        "print(\"{:<15}{}{}{:<15}{}\".format(\"X1_train Shape:\", X1_train.shape, \"\\t\", \"X1_test Shape:\", X1_test.shape))\n",
        "print(\"{:<15}{}{}{:<15}{}\".format(\"X2_train Shape:\", X2_train.shape, \"\\t\", \"X2_test Shape:\", X2_test.shape))\n",
        "print(\"{:<15}{}{}{:<15}{}\".format(\"X3_train Shape:\", X3_train.shape, \"\\t\", \"X3_test Shape:\", X3_test.shape))\n",
        "print(\"{:<15}{}{}{:<15}{}\".format(\"Y_train Shape:\", Y_train.shape, \"\\t\", \"Y_test Shape:\", Y_test.shape))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGbTMDOwVd_s"
      },
      "source": [
        "## Part 3. Perform a Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "ET4kuqIWVd_s"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[500] -> Preds_Y1: 506604.5707911067\n",
            "[600] -> Preds_Y1: 605620.8964563312\n",
            "[700] -> Preds_Y1: 704637.222121556\n",
            "[800] -> Preds_Y1: 803653.5477867809\n",
            "---------------------------------------\n",
            "[500] -> Preds_Y2: 506604.5707911067\n",
            "[600] -> Preds_Y2: 605620.8964563312\n",
            "[700] -> Preds_Y2: 704637.222121556\n",
            "[800] -> Preds_Y2: 803653.5477867809\n",
            "---------------------------------------\n",
            "X1| Score: 0.5216101556308503\n",
            "---------------------------------------\n",
            "X2| Score: 0.6141402305954329\n",
            "---------------------------------------\n",
            "x1 | Coefficients: \n",
            " [990.16325665]\n",
            "x1 | Intercept: 11522.942464983149\n",
            "---------------------------------------\n",
            "x2 | Coefficients: \n",
            " [1128.56378403]\n",
            "x2 | Intercept: -24581.02433657489\n"
          ]
        }
      ],
      "source": [
        "# Use sklearn to train a model on the training set\n",
        "\n",
        "# Temperature\n",
        "clf_x1 = LinearRegression()\n",
        "clf_x1.fit(X1_train, Y_train)\n",
        "\n",
        "# KCL\n",
        "clf_x2 = LinearRegression()\n",
        "clf_x2.fit(X2_train, Y_train)\n",
        "\n",
        "# # Make predictions using the testing set\n",
        "# y_pred = clf.predict(X_test)\n",
        "\n",
        "# # The mean squared error\n",
        "# print(\"Mean squared error: %.2f\" % mean_squared_error(Y_test, y_pred))\n",
        "# # The coefficient of determination: 1 is perfect prediction\n",
        "# print(\"Coefficient of determination: %.2f\" % r2_score(Y_test, y_pred))\n",
        "\n",
        "# Plot outputs\n",
        "# plt.scatter(X_test, Y_test, color=\"black\")\n",
        "# plt.plot(X_test, y_pred, color=\"blue\", linewidth=3)\n",
        "\n",
        "# plt.xticks(())\n",
        "# plt.yticks(())\n",
        "\n",
        "# plt.show()\n",
        "# \n",
        "# https://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html#sphx-glr-auto-examples-linear-model-plot-ols-py\n",
        "# -----------------------------------------------\n",
        "\n",
        "# Create a sample datapoint and predict the output of that sample with the trained model\n",
        "sample = [[500], [600], [700], [800]]\n",
        "\n",
        "preds_y1 = clf_x1.predict(sample)\n",
        "for idx, pred in enumerate(preds_y1):\n",
        "    print(str(sample[idx]) + \" -> Preds_Y1:\", pred)\n",
        "\n",
        "print(\"---------------------------------------\")\n",
        "\n",
        "preds_y2 = clf_x2.predict(sample)\n",
        "for idx, pred in enumerate(preds_y1):\n",
        "    print(str(sample[idx]) + \" -> Preds_Y2:\", pred)\n",
        "\n",
        "# Report on the score for that model, in your own words (markdown, not code) explain what the score means\n",
        "print(\"---------------------------------------\")\n",
        "print(\"X1| Score:\", clf_x1.score(X1_test, Y_test))\n",
        "print(\"---------------------------------------\")\n",
        "print(\"X2| Score:\", clf_x2.score(X2_test, Y_test))\n",
        "\n",
        "# Explanation\n",
        "# Using linearRegression algorithm, we traind the data set X and Y, predicting new Ys depends on sample datapoints.\n",
        "# Based on the scores, we can tell how accurately the chosen algorithm woulde predict outputs by given trained dataset\n",
        "# ; the hight score means higher accuratcy in predecting outouts. In our case, score is 88% which means linearRegression \n",
        "# algorithm has 88% accuracy to predict expanding size of the slime by temperature and amounts of KCL after one day.\n",
        "   \n",
        "# Extract the coefficents and intercept from the model and write an equation for your h(x) using LaTeX\n",
        "print(\"---------------------------------------\")\n",
        "print(\"x1 | Coefficients: \\n\", clf_x1.coef_)\n",
        "print(\"x1 | Intercept:\", clf_x1.intercept_ )\n",
        "\n",
        "print(\"---------------------------------------\")\n",
        "\n",
        "print(\"x2 | Coefficients: \\n\", clf_x2.coef_)\n",
        "print(\"x2 | Intercept:\", clf_x2.intercept_ )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {},
      "outputs": [],
      "source": [
        "# y      : response variable\n",
        "# n      : number of features\n",
        "# x_n    : n-th feature\n",
        "# beta_n: regression coefficient(weight) of the n-th feature\n",
        "# beta  : y-intercept\n",
        "\n",
        "# y = beta + beta_1(x_1) + beta_2(x_2) + .... + beta_n(x_n) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# H_temp(x) respects to Temperature"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\\begin{gather*}\n",
        "h(x) = 876.56x + 1032.21x - 420227.34\n",
        "\\end{gather*}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBFDiIDcVd_t"
      },
      "source": [
        "Sample equation: $E = mc^2$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mY_nbq4rVd_t"
      },
      "source": [
        "## Part 4. Use Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "Se13DqEGVd_t"
      },
      "outputs": [],
      "source": [
        "# Use the cross_val_score function to repeat your experiment across many shuffles of the data\n",
        "\n",
        "# Report on their finding and their significance\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJpNUSTzVd_u"
      },
      "source": [
        "## Part 5. Using Polynomial Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "lMuA8pgHVd_u"
      },
      "outputs": [
        {
          "ename": "NotFittedError",
          "evalue": "This LinearRegression instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[1;32md:\\gitprojects\\CSC448-AI\\CSC448_Seo_Jinho_AS03.ipynb Cell 16'\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/gitprojects/CSC448-AI/CSC448_Seo_Jinho_AS03.ipynb#ch0000015?line=3'>4</a>\u001b[0m clf_x3\u001b[39m.\u001b[39mfit(X1_train, Y_train)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/gitprojects/CSC448-AI/CSC448_Seo_Jinho_AS03.ipynb#ch0000015?line=5'>6</a>\u001b[0m sample \u001b[39m=\u001b[39m [[\u001b[39m500\u001b[39m, \u001b[39m500\u001b[39m], [\u001b[39m600\u001b[39m, \u001b[39m600\u001b[39m], [\u001b[39m700\u001b[39m, \u001b[39m700\u001b[39m], [\u001b[39m800\u001b[39m, \u001b[39m800\u001b[39m]]\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/gitprojects/CSC448-AI/CSC448_Seo_Jinho_AS03.ipynb#ch0000015?line=6'>7</a>\u001b[0m preds_y \u001b[39m=\u001b[39m clf\u001b[39m.\u001b[39;49mpredict(sample)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/gitprojects/CSC448-AI/CSC448_Seo_Jinho_AS03.ipynb#ch0000015?line=8'>9</a>\u001b[0m \u001b[39mfor\u001b[39;00m idx, pred \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(preds_y):\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/gitprojects/CSC448-AI/CSC448_Seo_Jinho_AS03.ipynb#ch0000015?line=9'>10</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mstr\u001b[39m(sample[idx]) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m -> Preds_Y:\u001b[39m\u001b[39m\"\u001b[39m, pred)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_base.py:362\u001b[0m, in \u001b[0;36mLinearModel.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/pinea/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/linear_model/_base.py?line=347'>348</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m    <a href='file:///c%3A/Users/pinea/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/linear_model/_base.py?line=348'>349</a>\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/pinea/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/linear_model/_base.py?line=349'>350</a>\u001b[0m \u001b[39m    Predict using the linear model.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/pinea/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/linear_model/_base.py?line=350'>351</a>\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/pinea/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/linear_model/_base.py?line=359'>360</a>\u001b[0m \u001b[39m        Returns predicted values.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/pinea/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/linear_model/_base.py?line=360'>361</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/pinea/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/linear_model/_base.py?line=361'>362</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_decision_function(X)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_base.py:343\u001b[0m, in \u001b[0;36mLinearModel._decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/pinea/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/linear_model/_base.py?line=341'>342</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_decision_function\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[1;32m--> <a href='file:///c%3A/Users/pinea/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/linear_model/_base.py?line=342'>343</a>\u001b[0m     check_is_fitted(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    <a href='file:///c%3A/Users/pinea/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/linear_model/_base.py?line=344'>345</a>\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_data(X, accept_sparse\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mcsr\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcsc\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcoo\u001b[39m\u001b[39m\"\u001b[39m], reset\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    <a href='file:///c%3A/Users/pinea/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/linear_model/_base.py?line=345'>346</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m safe_sparse_dot(X, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcoef_\u001b[39m.\u001b[39mT, dense_output\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintercept_\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1222\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/pinea/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/utils/validation.py?line=1216'>1217</a>\u001b[0m     fitted \u001b[39m=\u001b[39m [\n\u001b[0;32m   <a href='file:///c%3A/Users/pinea/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/utils/validation.py?line=1217'>1218</a>\u001b[0m         v \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m \u001b[39mvars\u001b[39m(estimator) \u001b[39mif\u001b[39;00m v\u001b[39m.\u001b[39mendswith(\u001b[39m\"\u001b[39m\u001b[39m_\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m v\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39m__\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   <a href='file:///c%3A/Users/pinea/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/utils/validation.py?line=1218'>1219</a>\u001b[0m     ]\n\u001b[0;32m   <a href='file:///c%3A/Users/pinea/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/utils/validation.py?line=1220'>1221</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m fitted:\n\u001b[1;32m-> <a href='file:///c%3A/Users/pinea/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/utils/validation.py?line=1221'>1222</a>\u001b[0m     \u001b[39mraise\u001b[39;00m NotFittedError(msg \u001b[39m%\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mtype\u001b[39m(estimator)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m})\n",
            "\u001b[1;31mNotFittedError\u001b[0m: This LinearRegression instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
          ]
        }
      ],
      "source": [
        "# Using the PolynomialFeatures library perform another regression on an augmented dataset of degree 2\n",
        "\n",
        "clf_x3 = LinearRegression()\n",
        "clf_x3.fit(X1_train, Y_train)\n",
        "\n",
        "sample = [[500, 500], [600, 600], [700, 700], [800, 800]]\n",
        "preds_y = clf.predict(sample)\n",
        "\n",
        "for idx, pred in enumerate(preds_y):\n",
        "    print(str(sample[idx]) + \" -> Preds_Y:\", pred)\n",
        "\n",
        "\n",
        "# Report on the score for that model, in your own words (markdown, not code) explain what the score means\n",
        "print(\"\\nScore:\", clf.score(X_test, Y_test))\n",
        "\n",
        "# Explanation\n",
        "# Using linearRegression algorithm, we traind the data set X and Y, predicting new Ys depends on sample datapoints.\n",
        "# Based on the scores, we can tell how accurately the chosen algorithm woulde predict outputs by given trained dataset\n",
        "# ; the hight score means higher accuratcy in predecting outouts. In our case, score is 88% which means linearRegression \n",
        "# algorithm has 88% accuracy to predict expanding size of the slime by temperature and amounts of KCL after one day.\n",
        "   \n",
        "# Extract the coefficents and intercept from the model and write an equation for your h(x) using LaTeX\n",
        "print(\"\\nCoefficients: \\n\", clf.coef_)\n",
        "print(\"Intercept:\", clf.intercept_ )\n",
        "\n",
        "# Report on the metrics and output the resultant equation as you did in Part 3."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "CSC448_Seo_Jinho_AS03.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
